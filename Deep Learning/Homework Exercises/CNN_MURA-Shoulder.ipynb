{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import gc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/tgeorgiopoulos/Downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1 = mpimg.imread(path+'/MURA-v1.1/train/XR_FINGER/patient03400/study1_positive/image2.png')\n",
    "img2 = mpimg.imread(path+'/MURA-v1.1/train/XR_ELBOW/patient00011/study1_negative/image2.png')\n",
    "img3 = mpimg.imread(path+'/MURA-v1.1/train/XR_HAND/patient00051/study1_negative/image1.png')\n",
    "img4 = mpimg.imread(path+'/MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image2.png')\n",
    "\n",
    "plt.subplot(221); plt.hist(img1)\n",
    "plt.subplot(222); plt.hist(img2)\n",
    "plt.subplot(223); plt.hist(img3)\n",
    "plt.subplot(224); plt.hist(img4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images have grayscale values between 0 and 1. So, there is no need for rescaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the images from csv and creating a panda frame with the paths and the labels for each image.\n",
    "train_df = pd.read_csv(path+'/MURA-v1.1/train_image_paths.csv',names = ['paths','label'],\n",
    "                       skiprows=9651, nrows=5106)\n",
    "valid_df = pd.read_csv(path+'/MURA-v1.1/valid_image_paths.csv',names = ['paths','label'],\n",
    "                       skiprows=2736, nrows=461)\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    if \"positive\" in train_df.iloc[index,0]:\n",
    "        train_df.iloc[index,1] = 1\n",
    "    elif \"negative\" in train_df.iloc[index,0]:\n",
    "        train_df.iloc[index,1] = 0\n",
    "\n",
    "for index, row in valid_df.iterrows():\n",
    "    if \"positive\" in valid_df.iloc[index,0]:\n",
    "        valid_df.iloc[index,1] = 1\n",
    "    elif \"negative\" in valid_df.iloc[index,0]:\n",
    "        valid_df.iloc[index,1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply data augmentation to the train dataset and convert all the images to (50,50) dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5106 images belonging to 2 classes.\n",
      "Found 461 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(samplewise_center = True,\n",
    "                                   samplewise_std_normalization=True,\n",
    "                                   rotation_range = 40, \n",
    "                                   width_shift_range = 0.1, \n",
    "                                   height_shift_range = 0.1,\n",
    "                                   zoom_range = 0.01, \n",
    "                                   horizontal_flip = True,\n",
    "                                   vertical_flip = True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                                    directory=path,\n",
    "                                                    x_col='paths',\n",
    "                                                    y_col='label',\n",
    "                                                    has_ext=True,\n",
    "                                                    batch_size=8,\n",
    "                                                    class_mode='binary',\n",
    "                                                    shuffle=True,\n",
    "                                                    target_size=(50,50),\n",
    "                                                    color_mode='grayscale')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(samplewise_center = True,\n",
    "                                   samplewise_std_normalization = True,\n",
    "                                   rotation_range = 0, \n",
    "                                   width_shift_range = 0., \n",
    "                                   height_shift_range = 0.,\n",
    "                                   zoom_range = 0.0, \n",
    "                                   horizontal_flip = False,\n",
    "                                   vertical_flip = False)\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_dataframe(dataframe=valid_df,\n",
    "                                                         directory=path,\n",
    "                                                         x_col='paths',\n",
    "                                                         y_col='label',\n",
    "                                                         has_ext=True,\n",
    "                                                         batch_size=8,\n",
    "                                                         class_mode='binary',\n",
    "                                                         shuffle=False,\n",
    "                                                         target_size=(50,50),\n",
    "                                                         color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(128, kernel_size = (5,5), activation=\"relu\",input_shape=(50, 50, 1)),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(4,4)),\n",
    "        tf.keras.layers.Conv2D(256, kernel_size = (5,5), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(4,4)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = multi_gpu_model(model_conv, gpus=2)\n",
    "model.compile(tf.keras.optimizers.Adam(), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=5,\n",
    "                              steps_per_epoch=500,\n",
    "                              validation_data=validation_generator,\n",
    "                              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "511/511 [==============================] - 21s 41ms/step - loss: 10.9584 - acc: 0.3126 - val_loss: 5.1684 - val_acc: 0.6758\n",
      "Epoch 2/5\n",
      "511/511 [==============================] - 20s 39ms/step - loss: 10.9584 - acc: 0.3126 - val_loss: 5.1684 - val_acc: 0.6758\n",
      "Epoch 3/5\n",
      "511/511 [==============================] - 21s 41ms/step - loss: 10.9561 - acc: 0.3128 - val_loss: 5.1684 - val_acc: 0.6758\n",
      "Epoch 4/5\n",
      "511/511 [==============================] - 21s 41ms/step - loss: 10.9514 - acc: 0.3131 - val_loss: 5.1684 - val_acc: 0.6758\n",
      "Epoch 5/5\n",
      "511/511 [==============================] - 21s 41ms/step - loss: 10.9584 - acc: 0.3126 - val_loss: 5.1684 - val_acc: 0.6758\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(200, 150, 1)),\n",
    "    tf.keras.layers.Dense(12, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"softmax\")])\n",
    "model = multi_gpu_model(model, gpus=2)\n",
    "model.compile(tf.keras.optimizers.Adam(), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=5,\n",
    "                              validation_data=validation_generator,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(50, 50, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "        conv_base,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1024, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = multi_gpu_model(model, gpus=2)\n",
    "model.compile(tf.keras.optimizers.Adam(), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=50,\n",
    "                              validation_data=validation_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
